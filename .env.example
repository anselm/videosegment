# LLM Provider Configuration
# Options: 'claude' or 'ollama'
LLM_PROVIDER=ollama

# Claude Configuration (required if LLM_PROVIDER=claude)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Ollama Configuration (required if LLM_PROVIDER=ollama)
# Available models: llama3.2:latest, llama3.2-vision:latest, gemma3:1b
OLLAMA_MODEL=llama3.2:latest
OLLAMA_BASE_URL=http://localhost:11434

# WhisperX Configuration
WHISPERX_API_URL=http://localhost:9010
